{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "At this point, `idlmav` was tested with a more diverse set of models than the convolutional image classification models it was initially developed with. The following models were tested:\n",
    "\n",
    "| Model          | Modality        | Task                           | Parameters | Notebook link                                                                            |\n",
    "| -----          | --------        | ----                           | ---------: | -------------                                                                            |\n",
    "| MobileNetV3    | Vision          | Image classification           | ~1.5M      | [15_explore_misc_models_vision.ipynb](./15_explore_misc_models_vision.ipynb)             |\n",
    "| EfficientNetV2 | Vision          | Image classification           | ~8M        | [15_explore_misc_models_vision.ipynb](./15_explore_misc_models_vision.ipynb)             |\n",
    "| Yolov11 nano   | Vision          | Object detection               | ~6M        | [15_explore_misc_models_vision.ipynb](./15_explore_misc_models_vision.ipynb)             |\n",
    "| CLIP           | Multi-modal     | Vision-language understanding  | ~86M       | [15_explore_misc_models_vision.ipynb](./15_explore_misc_models_vision.ipynb)             |\n",
    "| Wav2Vec        | Speech/audio    | Speech-to-text                 | ~95M       | [15_explore_misc_models_speech_audio.ipynb](./15_explore_misc_models_speech_audio.ipynb) |\n",
    "| Whisper Tiny   | Speech/audio    | Speech-to-text                 | ~39M       | [15_explore_misc_models_speech_audio.ipynb](./15_explore_misc_models_speech_audio.ipynb) |\n",
    "| DistilBERT     | NLP             | Text classification            | ~66M       | [15_explore_misc_models_nlp.ipynb](./15_explore_misc_models_nlp.ipynb)                   |\n",
    "| BERT mini      | NLP             | Text classification            | ~11M       | [15_explore_misc_models_nlp.ipynb](./15_explore_misc_models_nlp.ipynb)                   |\n",
    "| ALBERT Lite    | NLP             | Natural language understanding | ~12M       | [15_explore_misc_models_nlp.ipynb](./15_explore_misc_models_nlp.ipynb)                   |\n",
    "| T5-Small       | NLP             | Text-to-text                   | ~60M       | [15_explore_misc_models_nlp.ipynb](./15_explore_misc_models_nlp.ipynb)                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial run (after [14_test_skip_connections.ipynb](./14_test_skip_connections.ipynb))\n",
    "* MobileNetV3 small and EfficientNetV2 small already displayed nicely\n",
    "  * It is necessary to pan and zoom out and in a few times to really make sense of these networks\n",
    "  * The interactive widget makes this much easier than the static figure\n",
    "  * Adding the overview panel is also very valuable for these two models\n",
    "* For most other models, errors were produced associated with `torch.fx.symbolic_trace`. The errors included the following:\n",
    "  * `TraceError: symbolically traced variables cannot be used as inputs to control flow`, for the following underlying reasons:\n",
    "    *  The forward pass has multiple input parameters, some of which determine control flow\n",
    "    *  The forward pass performs input parameter validation on the dimensionality of input tensors\n",
    "  * `ValueError: You cannot specify both input_ids and inputs_embeds at the same time`\n",
    "    * Typical for BERT NLP models that provide both inputs and require the user to specify only one\n",
    "  * `TraceError: Proxy object cannot be iterated. This can be attempted when the Proxy is used in a loop or as a *args or **kwargs function argument.`\n",
    "    * e.g. `YOLO` calling `chunk` on a Tensor for which `fx` creates a proxy variable\n",
    "    * This prevented `idlmav` from displaying graphs for these models\n",
    "* The above errors prevented `idlmav` from displaying any graphs for these models\n",
    "* Remedies to these issues were developed in [16_explore_multiple_control_paths.ipynb](./16_explore_multiple_control_paths.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
